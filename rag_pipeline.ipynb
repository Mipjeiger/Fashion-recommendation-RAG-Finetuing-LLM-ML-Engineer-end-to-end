{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline \u2014 E-Commerce Revenue Analysis\n",
    "Qdrant + HuggingFace + LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook-safe ROOT_DIR \u2014 no __file__ needed\n",
    "ROOT_DIR = Path(os.getcwd())\n",
    "\n",
    "ENV_PATH = ROOT_DIR / \".env\"\n",
    "load_dotenv(dotenv_path=ENV_PATH)\n",
    "\n",
    "# Config\n",
    "HF_HOME = os.getenv(\"HF_HOME\")\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "Qdrant_API_KEY = os.getenv(\"Qdrant_API_KEY\")\n",
    "Qdrant_Cluster_Endpoint = os.getenv(\"Qdrant_Cluster_Endpoint\")\n",
    "\n",
    "# Validate \u2014 fail fast with a clear message if any key is missing\n",
    "assert Qdrant_Cluster_Endpoint, \"Qdrant_Cluster_Endpoint is not set in .env\"\n",
    "assert Qdrant_API_KEY,          \"Qdrant_API_KEY is not set in .env\"\n",
    "assert HF_TOKEN,                \"HF_TOKEN is not set in .env\"\n",
    "\n",
    "print(\"Environment variables loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Qdrant Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(\n",
    "    url=Qdrant_Cluster_Endpoint,\n",
    "    api_key=Qdrant_API_KEY\n",
    ")\n",
    "print(f\"Connected to Qdrant cloud at {Qdrant_Cluster_Endpoint} successfully.\")\n",
    "\n",
    "collections = qdrant_client.get_collections()\n",
    "print(f\"Collections: {collections}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs locally \u2014 no HuggingFace token needed\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "print(\"Embedding model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load or Create Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    vector_store = QdrantVectorStore.from_existing_collection(\n",
    "        client=qdrant_client,\n",
    "        collection_name=\"ecommerce_revenue_analysis\",\n",
    "        embedding=embedding\n",
    "    )\n",
    "    print(\"Vector store loaded from existing collection.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Collection not found: {e}. Creating from documents...\")\n",
    "\n",
    "    loader = PyPDFLoader(str(ROOT_DIR / \"ai_engineer\" / \"FAISS\" / \"Docs\" / \"PDF_ecommerce_revenue.pdf\"))\n",
    "    documents = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.split_documents(documents=documents)\n",
    "\n",
    "    vector_store = QdrantVectorStore.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedding,\n",
    "        client=qdrant_client,\n",
    "        collection_name=\"ecommerce_revenue_analysis\"\n",
    "    )\n",
    "    print(\"Vector store created from documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load LLM from HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = HuggingFaceEndpoint(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    max_new_tokens=512,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=False,\n",
    "    huggingfacehub_api_token=HF_TOKEN,\n",
    "    temperature=0.5\n",
    ")\n",
    "llm = ChatHuggingFace(llm=endpoint)\n",
    "print(\"LLM loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an e-commerce senior business analyst.\n",
    "Use ONLY the following context from document to answer the question.\n",
    "If the context is insufficient to answer the question, make hypothesis based on your knowledge and reasoning.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Notes:\n",
    "1. Minimal 350 words explanation\n",
    "2. Explaining the reasoning process step by step, including any assumptions made and how you arrived at the conclusion.\n",
    "3. Provide detailed analysis and insights based on the retrieved context\n",
    "4. If the context does not contain specific data or figures relevant to document, infer possible as senior business analyst, and clearly state.\n",
    "5. Make it statement clearly based on similar to document, if nothing cite specific data or figures in source_pages, infer possible values based on industry standards and trends, and clearly state that these are assumptions.\n",
    "6. Do not hallucinate\n",
    "\"\"\")\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"RAG Chain created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run a Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the main revenue drivers?\"\n",
    "\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  }
 ]
}